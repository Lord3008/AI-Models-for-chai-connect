{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9cc17f",
   "metadata": {
    "papermill": {
     "duration": 0.00605,
     "end_time": "2025-04-20T17:07:11.455154",
     "exception": false,
     "start_time": "2025-04-20T17:07:11.449104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17855c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:07:11.465879Z",
     "iopub.status.busy": "2025-04-20T17:07:11.465469Z",
     "iopub.status.idle": "2025-04-20T17:07:18.767556Z",
     "shell.execute_reply": "2025-04-20T17:07:18.766323Z"
    },
    "papermill": {
     "duration": 7.310024,
     "end_time": "2025-04-20T17:07:18.769870",
     "exception": false,
     "start_time": "2025-04-20T17:07:11.459846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\r\n",
      "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\r\n",
      "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: faker\r\n",
      "Successfully installed faker-37.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7ce6e0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-20T17:07:18.782592Z",
     "iopub.status.busy": "2025-04-20T17:07:18.782176Z",
     "iopub.status.idle": "2025-04-20T17:07:18.912893Z",
     "shell.execute_reply": "2025-04-20T17:07:18.911606Z"
    },
    "papermill": {
     "duration": 0.139017,
     "end_time": "2025-04-20T17:07:18.914430",
     "exception": false,
     "start_time": "2025-04-20T17:07:18.775413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data generated and saved to 'synthetic_data.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Faker for realistic data\n",
    "fake = Faker()\n",
    "\n",
    "# Define possible skills\n",
    "SKILLS_POOL = [\n",
    "    \"React\", \"JavaScript\", \"Node.js\", \"Python\", \"Django\", \"Flask\",\n",
    "    \"Graphic Design\", \"Illustration\", \"UI/UX Design\", \"Data Visualization\",\n",
    "    \"TypeScript\", \"Tailwind CSS\", \"Animation\", \"Machine Learning\", \"SQL\"\n",
    "]\n",
    "\n",
    "# Define possible tones for portfolio and reviews\n",
    "TONES = [\"creative\", \"professional\", \"technical\"]\n",
    "\n",
    "# Generate 5 client projects\n",
    "def generate_clients(num=5):\n",
    "    clients = []\n",
    "    for i in range(num):\n",
    "        num_skills = random.randint(2, 4)\n",
    "        skills = random.sample(SKILLS_POOL, num_skills)\n",
    "        tone = random.choice(TONES)\n",
    "        project_description = (\n",
    "            f\"{fake.sentence(nb_words=6, variable_nb_words=True)} \"\n",
    "            f\"requiring {', '.join(skills)} for a {tone} project\"\n",
    "        ).capitalize()\n",
    "        clients.append({\n",
    "            \"client_id\": i + 1,\n",
    "            \"project_description\": project_description,\n",
    "            \"skills_required\": skills,\n",
    "            \"budget\": round(random.uniform(300, 2000), 2),\n",
    "            \"timeline\": f\"{random.randint(5, 30)} days\",\n",
    "            \"created_at\": datetime(2025, 4, 20, random.randint(8, 18), random.randint(0, 59)).isoformat()\n",
    "        })\n",
    "    return clients\n",
    "\n",
    "# Generate 10 freelancers\n",
    "def generate_freelancers(num=10):\n",
    "    freelancers = []\n",
    "    for i in range(num):\n",
    "        num_skills = random.randint(3, 5)\n",
    "        skills = random.sample(SKILLS_POOL, num_skills)\n",
    "        tone = random.choice(TONES)\n",
    "        num_portfolio_items = random.randint(2, 3)\n",
    "        portfolio_text = [\n",
    "            f\"{fake.sentence(nb_words=5, variable_nb_words=True)} {skill.lower()} {tone} project\".capitalize()\n",
    "            for skill in random.sample(skills, num_portfolio_items)\n",
    "        ]\n",
    "        num_experiences = random.randint(1, 3)\n",
    "        experience = [\n",
    "            {\n",
    "                \"duration\": f\"{random.randint(1, 7)} years\",\n",
    "                \"experience_description\": f\"{fake.sentence(nb_words=6, variable_nb_words=True)} {skill.lower()}\".capitalize()\n",
    "            }\n",
    "            for skill in random.sample(skills, num_experiences)\n",
    "        ]\n",
    "        freelancers.append({\n",
    "            \"freelancer_id\": i + 1,\n",
    "            \"skills\": skills,\n",
    "            \"experience\": experience,\n",
    "            \"portfolio_text\": portfolio_text,\n",
    "            \"availability\": random.choice([True, False]),\n",
    "            \"avg_rating\": round(random.uniform(3.5, 5.0), 2) if random.random() > 0.2 else 0.0,\n",
    "            \"rate\": round(random.uniform(20, 100), 2),\n",
    "            \"created_at\": datetime(2025, 4, random.randint(1, 19), random.randint(8, 18)).isoformat(),\n",
    "            \"updated_at\": datetime(2025, 4, 20, random.randint(8, 18)).isoformat()\n",
    "        })\n",
    "    return freelancers\n",
    "\n",
    "# Generate 3 reviews\n",
    "def generate_reviews(num=3, freelancer_ids=range(1, 11)):\n",
    "    reviews = []\n",
    "    selected_freelancers = random.sample(list(freelancer_ids), num)\n",
    "    for i, freelancer_id in enumerate(selected_freelancers, 1):\n",
    "        tone = random.choice(TONES)\n",
    "        reviews.append({\n",
    "            \"review_id\": i,\n",
    "            \"freelancer_id\": freelancer_id,\n",
    "            \"review_text\": f\"{fake.sentence(nb_words=6, variable_nb_words=True)} {tone} work\".capitalize(),\n",
    "            \"rating\": round(random.uniform(4.0, 5.0), 2),\n",
    "            \"created_at\": datetime(2025, 4, random.randint(10, 19), random.randint(8, 18)).isoformat()\n",
    "        })\n",
    "    return reviews\n",
    "\n",
    "# Generate data\n",
    "clients = generate_clients(5)\n",
    "freelancers = generate_freelancers(10)\n",
    "reviews = generate_reviews(3)\n",
    "\n",
    "# Combine data\n",
    "data = {\n",
    "    \"clients\": clients,\n",
    "    \"freelancers\": freelancers,\n",
    "    \"reviews\": reviews\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"synthetic_data.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "print(\"Synthetic data generated and saved to 'synthetic_data.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c55ce0c",
   "metadata": {
    "papermill": {
     "duration": 0.004893,
     "end_time": "2025-04-20T17:07:18.924894",
     "exception": false,
     "start_time": "2025-04-20T17:07:18.920001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac2a772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:07:18.936462Z",
     "iopub.status.busy": "2025-04-20T17:07:18.936132Z",
     "iopub.status.idle": "2025-04-20T17:07:18.946327Z",
     "shell.execute_reply": "2025-04-20T17:07:18.945145Z"
    },
    "papermill": {
     "duration": 0.018019,
     "end_time": "2025-04-20T17:07:18.947947",
     "exception": false,
     "start_time": "2025-04-20T17:07:18.929928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 clients, 10 freelancers, and 3 reviews from synthetic_data.json\n",
      "\n",
      "Sample Client:\n",
      "{\n",
      "  \"client_id\": 1,\n",
      "  \"project_description\": \"My subject media without. requiring animation, django, python, data visualization for a professional project\",\n",
      "  \"skills_required\": [\n",
      "    \"Animation\",\n",
      "    \"Django\",\n",
      "    \"Python\",\n",
      "    \"Data Visualization\"\n",
      "  ],\n",
      "  \"budget\": 1865.14,\n",
      "  \"timeline\": \"5 days\",\n",
      "  \"created_at\": \"2025-04-20T10:35:00\"\n",
      "}\n",
      "\n",
      "Sample Freelancer:\n",
      "{\n",
      "  \"freelancer_id\": 1,\n",
      "  \"skills\": [\n",
      "    \"Django\",\n",
      "    \"Node.js\",\n",
      "    \"Data Visualization\",\n",
      "    \"Tailwind CSS\",\n",
      "    \"TypeScript\"\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"duration\": \"1 years\",\n",
      "      \"experience_description\": \"Blood dream because seek several fish something. node.js\"\n",
      "    }\n",
      "  ],\n",
      "  \"portfolio_text\": [\n",
      "    \"Red drug modern. node.js technical project\",\n",
      "    \"Order meet easy. tailwind css technical project\",\n",
      "    \"Base smile role. data visualization technical project\"\n",
      "  ],\n",
      "  \"availability\": true,\n",
      "  \"avg_rating\": 4.84,\n",
      "  \"rate\": 42.31,\n",
      "  \"created_at\": \"2025-04-09T09:00:00\",\n",
      "  \"updated_at\": \"2025-04-20T10:00:00\"\n",
      "}\n",
      "\n",
      "Sample Review:\n",
      "{\n",
      "  \"review_id\": 1,\n",
      "  \"freelancer_id\": 1,\n",
      "  \"review_text\": \"Hold study small concern. creative work\",\n",
      "  \"rating\": 4.44,\n",
      "  \"created_at\": \"2025-04-18T16:00:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "def load_synthetic_data(file_path: str = \"synthetic_data.json\") -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Load synthetic data from a JSON file and return clients, freelancers, and reviews as separate lists.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file (default: 'synthetic_data.json').\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[Dict[str, Any]], List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "            - List of client dictionaries.\n",
    "            - List of freelancer dictionaries.\n",
    "            - List of review dictionaries.\n",
    "            \n",
    "    Raises:\n",
    "        FileNotFoundError: If the JSON file does not exist.\n",
    "        json.JSONDecodeError: If the JSON file is invalid.\n",
    "        KeyError: If expected keys ('clients', 'freelancers', 'reviews') are missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the JSON file\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract clients, freelancers, and reviews\n",
    "        clients = data[\"clients\"]\n",
    "        freelancers = data[\"freelancers\"]\n",
    "        reviews = data[\"reviews\"]\n",
    "        \n",
    "        # Validate data\n",
    "        if not all([clients, freelancers, reviews]):\n",
    "            raise KeyError(\"JSON file missing required keys: 'clients', 'freelancers', or 'reviews'\")\n",
    "        \n",
    "        print(f\"Loaded {len(clients)} clients, {len(freelancers)} freelancers, and {len(reviews)} reviews from {file_path}\")\n",
    "        return clients, freelancers, reviews\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON format in '{file_path}': {str(e)}\")\n",
    "        raise\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Missing required keys in JSON data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load data into variables\n",
    "        clients_data, freelancers_data, reviews_data = load_synthetic_data()\n",
    "        \n",
    "        # Print sample data for verification\n",
    "        print(\"\\nSample Client:\")\n",
    "        print(json.dumps(clients_data[0], indent=2))\n",
    "        \n",
    "        print(\"\\nSample Freelancer:\")\n",
    "        print(json.dumps(freelancers_data[0], indent=2))\n",
    "        \n",
    "        print(\"\\nSample Review:\")\n",
    "        print(json.dumps(reviews_data[0], indent=2))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264954a4",
   "metadata": {
    "papermill": {
     "duration": 0.004723,
     "end_time": "2025-04-20T17:07:18.957831",
     "exception": false,
     "start_time": "2025-04-20T17:07:18.953108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0558d13f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:07:18.969180Z",
     "iopub.status.busy": "2025-04-20T17:07:18.968906Z",
     "iopub.status.idle": "2025-04-20T17:07:24.966223Z",
     "shell.execute_reply": "2025-04-20T17:07:24.964982Z"
    },
    "papermill": {
     "duration": 6.005082,
     "end_time": "2025-04-20T17:07:24.967893",
     "exception": false,
     "start_time": "2025-04-20T17:07:18.962811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 clients, 10 freelancers, and 3 reviews from synthetic_data.json\n",
      "\n",
      "Sample Preprocessed Client:\n",
      "{\n",
      "  \"client_id\": 1,\n",
      "  \"project_description\": \"my subject medium without requiring animation django python data visualization for a professional project\",\n",
      "  \"skills_required\": [\n",
      "    \"Animation\",\n",
      "    \"Django\",\n",
      "    \"Python\",\n",
      "    \"Data Visualization\"\n",
      "  ],\n",
      "  \"budget\": 1865.14,\n",
      "  \"timeline\": \"5 days\",\n",
      "  \"created_at\": \"2025-04-20T10:35:00\"\n",
      "}\n",
      "\n",
      "Sample Preprocessed Freelancer:\n",
      "{\n",
      "  \"freelancer_id\": 1,\n",
      "  \"skills\": [\n",
      "    \"Django\",\n",
      "    \"Node.js\",\n",
      "    \"Data Visualization\",\n",
      "    \"Tailwind CSS\",\n",
      "    \"TypeScript\"\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"duration\": \"1 years\",\n",
      "      \"experience_description\": \"blood dream because seek several fish something node j\"\n",
      "    }\n",
      "  ],\n",
      "  \"portfolio_text\": \"red drug modern node j technical project order meet easy tailwind cs technical project base smile role data visualization technical project\",\n",
      "  \"availability\": true,\n",
      "  \"avg_rating\": 4.84,\n",
      "  \"rate\": 42.31,\n",
      "  \"created_at\": \"2025-04-09T09:00:00\",\n",
      "  \"updated_at\": \"2025-04-20T10:00:00\"\n",
      "}\n",
      "\n",
      "Sample Preprocessed Review:\n",
      "{\n",
      "  \"review_id\": 1,\n",
      "  \"freelancer_id\": 1,\n",
      "  \"review_text\": \"hold study small concern creative work\",\n",
      "  \"rating\": 4.44,\n",
      "  \"created_at\": \"2025-04-18T16:00:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from typing import List, Dict, Any, Union\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "def preprocess_text(text: str, remove_stopwords: bool = False, lemmatize: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess a single text string by cleaning and normalizing it.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to preprocess.\n",
    "        remove_stopwords (bool): If True, remove stopwords (default: False to preserve tone words).\n",
    "        lemmatize (bool): If True, lemmatize words (default: True).\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned and normalized text.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and extra spaces\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)  # Keep letters and spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords (optional)\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatize (optional)\n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_synthetic_data(clients: List[Dict[str, Any]], \n",
    "                            freelancers: List[Dict[str, Any]], \n",
    "                            reviews: List[Dict[str, Any]], \n",
    "                            join_portfolio: bool = True,\n",
    "                            include_experience: bool = True) -> tuple[List[Dict[str, Any]], List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Preprocess text fields in synthetic data (clients, freelancers, reviews).\n",
    "    \n",
    "    Args:\n",
    "        clients (List[Dict[str, Any]]): List of client dictionaries.\n",
    "        freelancers (List[Dict[str, Any]]): List of freelancer dictionaries.\n",
    "        reviews (List[Dict[str, Any]]): List of review dictionaries.\n",
    "        join_portfolio (bool): If True, join portfolio_text into a single string; else keep as list.\n",
    "        include_experience (bool): If True, preprocess experience_description and include in output.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[Dict[str, Any]], List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "            - Preprocessed clients with cleaned project_description.\n",
    "            - Preprocessed freelancers with cleaned portfolio_text and experience.\n",
    "            - Preprocessed reviews with cleaned review_text.\n",
    "    \"\"\"\n",
    "    # Copy data to avoid modifying originals\n",
    "    clients_processed = clients.copy()\n",
    "    freelancers_processed = freelancers.copy()\n",
    "    reviews_processed = reviews.copy()\n",
    "    \n",
    "    # Preprocess clients (project_description)\n",
    "    for client in clients_processed:\n",
    "        client['project_description'] = preprocess_text(client['project_description'])\n",
    "    \n",
    "    # Preprocess freelancers (portfolio_text, experience)\n",
    "    for freelancer in freelancers_processed:\n",
    "        # Process portfolio_text\n",
    "        if join_portfolio:\n",
    "            # Join portfolio_text into a single string\n",
    "            joined_text = ' '.join(freelancer['portfolio_text'])\n",
    "            freelancer['portfolio_text'] = preprocess_text(joined_text)\n",
    "        else:\n",
    "            # Process each portfolio_text entry separately\n",
    "            freelancer['portfolio_text'] = [preprocess_text(text) for text in freelancer['portfolio_text']]\n",
    "        \n",
    "        # Process experience (if included)\n",
    "        if include_experience:\n",
    "            for exp in freelancer['experience']:\n",
    "                exp['experience_description'] = preprocess_text(exp['experience_description'])\n",
    "    \n",
    "    # Preprocess reviews (review_text)\n",
    "    for review in reviews_processed:\n",
    "        review['review_text'] = preprocess_text(review['review_text'])\n",
    "    \n",
    "    return clients_processed, freelancers_processed, reviews_processed\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load synthetic data\n",
    "        clients_data, freelancers_data, reviews_data = load_synthetic_data(\"synthetic_data.json\")\n",
    "        \n",
    "        # Preprocess data\n",
    "        clients_proc, freelancers_proc, reviews_proc = preprocess_synthetic_data(\n",
    "            clients_data,\n",
    "            freelancers_data,\n",
    "            reviews_data,\n",
    "            join_portfolio=True,  # Join portfolio_text for BERT embeddings\n",
    "            include_experience=True  # Include experience_description\n",
    "        )\n",
    "        \n",
    "        # Print samples for verification\n",
    "        print(\"\\nSample Preprocessed Client:\")\n",
    "        print(json.dumps(clients_proc[0], indent=2))\n",
    "        \n",
    "        print(\"\\nSample Preprocessed Freelancer:\")\n",
    "        print(json.dumps(freelancers_proc[0], indent=2))\n",
    "        \n",
    "        print(\"\\nSample Preprocessed Review:\")\n",
    "        print(json.dumps(reviews_proc[0], indent=2))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to preprocess data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4cd968",
   "metadata": {
    "papermill": {
     "duration": 0.005171,
     "end_time": "2025-04-20T17:07:24.978461",
     "exception": false,
     "start_time": "2025-04-20T17:07:24.973290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a172f2",
   "metadata": {
    "papermill": {
     "duration": 0.004881,
     "end_time": "2025-04-20T17:07:24.988572",
     "exception": false,
     "start_time": "2025-04-20T17:07:24.983691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## To Generate Client and Freelancer Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cfc8963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:07:25.001117Z",
     "iopub.status.busy": "2025-04-20T17:07:25.000658Z",
     "iopub.status.idle": "2025-04-20T17:08:09.132308Z",
     "shell.execute_reply": "2025-04-20T17:08:09.131125Z"
    },
    "papermill": {
     "duration": 44.140364,
     "end_time": "2025-04-20T17:08:09.134041",
     "exception": false,
     "start_time": "2025-04-20T17:07:24.993677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 clients, 10 freelancers, and 3 reviews from synthetic_data.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518e465c382749e780243b8218e0271c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfabd0f8d7d4048be31e6f282e6adf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403b20c4e1814d8eb3f2bb1170a03f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5e632973bb457996ed0ac2a218fa53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 17:07:49.550843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745168869.840658      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745168869.919440      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4013407054524766b45bf21630aaec2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client embeddings shape: (5, 768)\n",
      "Freelancer embeddings shape: (10, 768)\n",
      "Similarity matrix shape: (5, 10)\n",
      "\n",
      "Sample Cosine Similarity Scores (Client 1 vs. Freelancers):\n",
      "Freelancer 1: 0.9290\n",
      "Freelancer 2: 0.8802\n",
      "Freelancer 3: 0.8979\n",
      "Freelancer 4: 0.9113\n",
      "Freelancer 5: 0.9116\n",
      "Freelancer 6: 0.9402\n",
      "Freelancer 7: 0.9331\n",
      "Freelancer 8: 0.9347\n",
      "Freelancer 9: 0.9456\n",
      "Freelancer 10: 0.9245\n",
      "\n",
      "Sample Client 1 Embedding (first 5 dimensions):\n",
      "[-0.08792603  0.0429019  -0.02656294 -0.20145981  0.00760244]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "def get_bert_embeddings(texts: List[str], model_name: str = 'distilbert-base-uncased', batch_size: int = 8) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate BERT embeddings for a list of texts using a pre-trained model.\n",
    "    \n",
    "    Args:\n",
    "        texts (List[str]): List of text strings to embed.\n",
    "        model_name (str): Hugging Face model name (default: 'distilbert-base-uncased').\n",
    "        batch_size (int): Batch size for processing texts (default: 8).\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Array of embeddings (shape: [len(texts), 768]).\n",
    "    \"\"\"\n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    # Process texts in batches\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize and encode\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Get embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            # Use [CLS] token embedding (first token)\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        \n",
    "        embeddings.append(batch_embeddings)\n",
    "    \n",
    "    # Concatenate embeddings\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def get_tfidf_embeddings(texts: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate TF-IDF embeddings for a list of texts.\n",
    "    \n",
    "    Args:\n",
    "        texts (List[str]): List of text strings to embed.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Array of TF-IDF vectors (sparse, converted to dense).\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    return tfidf_matrix.toarray()\n",
    "\n",
    "def extract_text_features(clients: List[Dict[str, Any]], \n",
    "                         freelancers: List[Dict[str, Any]], \n",
    "                         use_bert: bool = True) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract text features (BERT or TF-IDF embeddings) for project_description and portfolio_text.\n",
    "    \n",
    "    Args:\n",
    "        clients (List[Dict[str, Any]]): List of preprocessed client dictionaries.\n",
    "        freelancers (List[Dict[str, Any]]): List of preprocessed freelancer dictionaries.\n",
    "        use_bert (bool): If True, use BERT embeddings; else use TF-IDF (default: True).\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "            - Client embeddings (shape: [len(clients), 768] for BERT, or [len(clients), vocab_size] for TF-IDF).\n",
    "            - Freelancer embeddings (shape: [len(freelancers), 768] or [len(freelancers), vocab_size]).\n",
    "            - Cosine similarity matrix (shape: [len(clients), len(freelancers)]).\n",
    "    \"\"\"\n",
    "    # Extract text fields\n",
    "    client_texts = [client['project_description'] for client in clients]\n",
    "    freelancer_texts = [freelancer['portfolio_text'] for freelancer in freelancers]\n",
    "    \n",
    "    # Generate embeddings\n",
    "    if use_bert:\n",
    "        # Combine texts for efficiency (single model load)\n",
    "        all_texts = client_texts + freelancer_texts\n",
    "        all_embeddings = get_bert_embeddings(all_texts)\n",
    "        \n",
    "        # Split embeddings\n",
    "        client_embeddings = all_embeddings[:len(client_texts)]\n",
    "        freelancer_embeddings = all_embeddings[len(client_texts):]\n",
    "    else:\n",
    "        # TF-IDF embeddings\n",
    "        all_texts = client_texts + freelancer_texts\n",
    "        all_embeddings = get_tfidf_embeddings(all_texts)\n",
    "        \n",
    "        # Split embeddings\n",
    "        client_embeddings = all_embeddings[:len(client_texts)]\n",
    "        freelancer_embeddings = all_embeddings[len(client_texts):]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity_matrix = cosine_similarity(client_embeddings, freelancer_embeddings)\n",
    "    \n",
    "    return client_embeddings, freelancer_embeddings, similarity_matrix\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Notes:  This should run every day, so new freelancer can be included in recommendation\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load synthetic data\n",
    "        clients_data, freelancers_data, reviews_data = load_synthetic_data(\"synthetic_data.json\")\n",
    "        \n",
    "        # Preprocess data (join_portfolio=True for single string)\n",
    "        clients_proc, freelancers_proc, reviews_proc = preprocess_synthetic_data(\n",
    "            clients_data,\n",
    "            freelancers_data,\n",
    "            reviews_data,\n",
    "            join_portfolio=True,\n",
    "            include_experience=False  # Exclude experience for now\n",
    "        )\n",
    "        \n",
    "        # Extract features\n",
    "        client_emb, freelancer_emb, similarity_matrix = extract_text_features(\n",
    "            clients_proc,\n",
    "            freelancers_proc,\n",
    "            use_bert=True  # Use BERT embeddings\n",
    "        )\n",
    "        \n",
    "        # Print shapes and sample results\n",
    "        print(f\"Client embeddings shape: {client_emb.shape}\")\n",
    "        print(f\"Freelancer embeddings shape: {freelancer_emb.shape}\")\n",
    "        print(f\"Similarity matrix shape: {similarity_matrix.shape}\")\n",
    "        \n",
    "        # Print sample similarity scores\n",
    "        print(\"\\nSample Cosine Similarity Scores (Client 1 vs. Freelancers):\")\n",
    "        for i, score in enumerate(similarity_matrix[0]):\n",
    "            print(f\"Freelancer {i+1}: {score:.4f}\")\n",
    "        \n",
    "        # Print sample embedding (first 5 dimensions for brevity)\n",
    "        print(\"\\nSample Client 1 Embedding (first 5 dimensions):\")\n",
    "        print(client_emb[0][:5])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract features: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dff344",
   "metadata": {
    "papermill": {
     "duration": 0.006172,
     "end_time": "2025-04-20T17:08:09.147582",
     "exception": false,
     "start_time": "2025-04-20T17:08:09.141410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## To Find Similarity From a Client Data and All Freelancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cfb59a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:08:09.162067Z",
     "iopub.status.busy": "2025-04-20T17:08:09.161357Z",
     "iopub.status.idle": "2025-04-20T17:08:12.249081Z",
     "shell.execute_reply": "2025-04-20T17:08:12.247823Z"
    },
    "papermill": {
     "duration": 3.097038,
     "end_time": "2025-04-20T17:08:12.250854",
     "exception": false,
     "start_time": "2025-04-20T17:08:09.153816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 clients, 10 freelancers, and 3 reviews from synthetic_data.json\n",
      "\n",
      "Cosine Similarity Scores for New Client vs. Freelancers:\n",
      "Freelancer 1: 0.8763\n",
      "Freelancer 2: 0.8018\n",
      "Freelancer 3: 0.8278\n",
      "Freelancer 4: 0.8404\n",
      "Freelancer 5: 0.8293\n",
      "Freelancer 6: 0.9007\n",
      "Freelancer 7: 0.8556\n",
      "Freelancer 8: 0.8756\n",
      "Freelancer 9: 0.9041\n",
      "Freelancer 10: 0.8813\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def get_bert_embedding(text: str, model_name: str = 'distilbert-base-uncased') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate BERT embedding for a single text string.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to embed.\n",
    "        model_name (str): Hugging Face model name (default: 'distilbert-base-uncased').\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Embedding vector (shape: [768]).\n",
    "    \"\"\"\n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize and encode\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Get embedding\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use [CLS] token embedding\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    return embedding[0]  # Shape: [768]\n",
    "\n",
    "def compute_client_similarity(client_data: Dict[str, Any], \n",
    "                             freelancer_embeddings_file: str = \"freelancer_embeddings.npy\",\n",
    "                             freelancers_data: List[Dict[str, Any]] = None) -> List[float]:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between a client's project_description and each freelancer's portfolio_text.\n",
    "    \n",
    "    Args:\n",
    "        client_data (Dict[str, Any]): Client data with 'project_description' key.\n",
    "        freelancer_embeddings_file (str): Path to precomputed freelancer embeddings (default: 'freelancer_embeddings.npy').\n",
    "        freelancers_data (List[Dict[str, Any]]): Preprocessed freelancer data (optional, used if embeddings file is missing).\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: Cosine similarity scores for each freelancer (ordered by freelancer_id).\n",
    "        \n",
    "    Raises:\n",
    "        KeyError: If 'project_description' is missing in client_data.\n",
    "        FileNotFoundError: If freelancer_embeddings_file is missing and freelancers_data is not provided.\n",
    "    \"\"\"\n",
    "    # Validate client data\n",
    "    if 'project_description' not in client_data:\n",
    "        raise KeyError(\"client_data must contain 'project_description'\")\n",
    "    \n",
    "    # Preprocess client project_description\n",
    "    client_text = preprocess_text(client_data['project_description'])\n",
    "    \n",
    "    # Generate client embedding\n",
    "    client_embedding = get_bert_embedding(client_text).reshape(1, -1)  # Shape: [1, 768]\n",
    "    \n",
    "    # Load or compute freelancer embeddings\n",
    "    try:\n",
    "        # Try loading precomputed embeddings\n",
    "        freelancer_embeddings = np.load(freelancer_embeddings_file)\n",
    "    except FileNotFoundError:\n",
    "        if freelancers_data is None:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Freelancer embeddings file '{freelancer_embeddings_file}' not found, \"\n",
    "                \"and freelancers_data not provided\"\n",
    "            )\n",
    "        # Compute embeddings on-the-fly\n",
    "        freelancer_texts = [freelancer['portfolio_text'] for freelancer in freelancers_data]\n",
    "        freelancer_embeddings = np.vstack([\n",
    "            get_bert_embedding(text) for text in freelancer_texts\n",
    "        ])\n",
    "        # Save for future use\n",
    "        np.save(freelancer_embeddings_file, freelancer_embeddings)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity_scores = cosine_similarity(client_embedding, freelancer_embeddings)[0]\n",
    "    \n",
    "    return similarity_scores.tolist()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load synthetic data\n",
    "        clients_data, freelancers_data, reviews_data = load_synthetic_data(\"synthetic_data.json\")\n",
    "        \n",
    "        # Preprocess data (join_portfolio=True for single string)\n",
    "        _, freelancers_proc, _ = preprocess_synthetic_data(\n",
    "            clients_data,\n",
    "            freelancers_data,\n",
    "            reviews_data,\n",
    "            join_portfolio=True,\n",
    "            include_experience=False\n",
    "        )\n",
    "        \n",
    "        # Example: Assume precomputed freelancer embeddings exist\n",
    "        # (Run extract_text_features.py first to generate freelancer_embeddings.npy)\n",
    "        \n",
    "        # New client data\n",
    "        new_client = {\n",
    "            \"project_description\": \"REACT\"\n",
    "        }\n",
    "        \n",
    "        # Compute similarity scores\n",
    "        similarity_scores = compute_client_similarity(\n",
    "            client_data=new_client,\n",
    "            freelancer_embeddings_file=\"freelancer_embeddings.npy\",\n",
    "            freelancers_data=freelancers_proc  # Fallback if file missing\n",
    "        )\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nCosine Similarity Scores for New Client vs. Freelancers:\")\n",
    "        for i, score in enumerate(similarity_scores, 1):\n",
    "            print(f\"Freelancer {i}: {score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compute similarities: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c30cd",
   "metadata": {
    "papermill": {
     "duration": 0.005721,
     "end_time": "2025-04-20T17:08:12.262918",
     "exception": false,
     "start_time": "2025-04-20T17:08:12.257197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tone Analysis\n",
    "\n",
    "But i think for now we dont use tone analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b67839e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:08:12.277509Z",
     "iopub.status.busy": "2025-04-20T17:08:12.277182Z",
     "iopub.status.idle": "2025-04-20T17:08:12.287767Z",
     "shell.execute_reply": "2025-04-20T17:08:12.286272Z"
    },
    "papermill": {
     "duration": 0.020111,
     "end_time": "2025-04-20T17:08:12.289456",
     "exception": false,
     "start_time": "2025-04-20T17:08:12.269345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# from typing import List, Dict, Any, Tuple\n",
    "# import torch\n",
    "# from faker import Faker\n",
    "\n",
    "# # Initialize Faker for synthetic data\n",
    "# fake = Faker()\n",
    "\n",
    "# def generate_synthetic_tone_data(num_samples_per_class: int = 100) -> Tuple[List[str], List[int]]:\n",
    "#     \"\"\"\n",
    "#     Generate synthetic labeled data for tone classification (creative, professional, technical).\n",
    "    \n",
    "#     Args:\n",
    "#         num_samples_per_class (int): Number of samples per tone class (default: 100).\n",
    "        \n",
    "#     Returns:\n",
    "#         Tuple[List[str], List[int]]: Texts and corresponding labels (0: creative, 1: professional, 2: technical).\n",
    "#     \"\"\"\n",
    "#     tones = ['creative', 'professional', 'technical']\n",
    "#     texts = []\n",
    "#     labels = []\n",
    "    \n",
    "#     for tone_idx, tone in enumerate(tones):\n",
    "#         for _ in range(num_samples_per_class):\n",
    "#             if tone == 'creative':\n",
    "#                 text = f\"{fake.sentence(nb_words=6)} vibrant {tone} design project\"\n",
    "#             elif tone == 'professional':\n",
    "#                 text = f\"{fake.sentence(nb_words=6)} reliable {tone} service delivery\"\n",
    "#             else:  # technical\n",
    "#                 text = f\"{fake.sentence(nb_words=6)} scalable {tone} system implementation\"\n",
    "#             texts.append(text)\n",
    "#             labels.append(tone_idx)\n",
    "    \n",
    "#     return texts, labels\n",
    "\n",
    "# def train_tone_classifier(texts: List[str], labels: List[int], use_bert: bool = True, model_name: str = 'distilbert-base-uncased') -> Any:\n",
    "#     \"\"\"\n",
    "#     Train a tone classifier (BERT or Logistic Regression) on labeled texts.\n",
    "    \n",
    "#     Args:\n",
    "#         texts (List[str]): Preprocessed texts for training.\n",
    "#         labels (List[int]): Labels (0: creative, 1: professional, 2: technical).\n",
    "#         use_bert (bool): If True, use BERT; else use Logistic Regression with TF-IDF (default: True).\n",
    "#         model_name (str): Hugging Face model name for BERT (default: 'distilbert-base-uncased').\n",
    "        \n",
    "#     Returns:\n",
    "#         Any: Trained model (BERT Trainer or LogisticRegression).\n",
    "#     \"\"\"\n",
    "#     if use_bert:\n",
    "#         # Tokenize texts\n",
    "#         tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#         encodings = tokenizer(\n",
    "#             texts,\n",
    "#             padding=True,\n",
    "#             truncation=True,\n",
    "#             max_length=128,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "        \n",
    "#         # Create dataset\n",
    "#         class ToneDataset(torch.utils.data.Dataset):\n",
    "#             def __init__(self, encodings, labels):\n",
    "#                 self.encodings = encodings\n",
    "#                 self.labels = labels\n",
    "            \n",
    "#             def __getitem__(self, idx):\n",
    "#                 item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "#                 item['labels'] = torch.tensor(self.labels[idx])\n",
    "#                 return item\n",
    "            \n",
    "#             def __len__(self):\n",
    "#                 return len(self.labels)\n",
    "        \n",
    "#         dataset = ToneDataset(encodings, labels)\n",
    "        \n",
    "#         # Split into train and validation (80-20)\n",
    "#         train_size = int(0.8 * len(dataset))\n",
    "#         train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "        \n",
    "#         # Initialize model\n",
    "#         model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "        \n",
    "#         # Training arguments\n",
    "#         training_args = TrainingArguments(\n",
    "#             output_dir=\"./tone_classifier\",\n",
    "#             num_train_epochs=3,\n",
    "#             per_device_train_batch_size=8,\n",
    "#             per_device_eval_batch_size=8,\n",
    "#             warmup_steps=10,\n",
    "#             weight_decay=0.01,\n",
    "#             logging_dir=\"./logs\",\n",
    "#             logging_steps=10,\n",
    "#             eval_strategy=\"epoch\",\n",
    "#             save_strategy=\"epoch\",\n",
    "#             load_best_model_at_end=True\n",
    "#         )\n",
    "        \n",
    "#         # Initialize trainer\n",
    "#         trainer = Trainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             train_dataset=train_dataset,\n",
    "#             eval_dataset=val_dataset,\n",
    "#             compute_metrics=lambda p: {\n",
    "#                 \"accuracy\": accuracy_score(p.label_ids, np.argmax(p.predictions, axis=1)),\n",
    "#                 \"f1\": f1_score(p.label_ids, np.argmax(p.predictions, axis=1), average='weighted')\n",
    "#             }\n",
    "#         )\n",
    "        \n",
    "#         # Train\n",
    "#         trainer.train()\n",
    "#         return trainer\n",
    "    \n",
    "#     else:\n",
    "#         # TF-IDF with Logistic Regression\n",
    "#         vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "#         X = vectorizer.fit_transform(texts)\n",
    "#         model = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "#         model.fit(X, labels)\n",
    "#         return model, vectorizer\n",
    "\n",
    "# def predict_tone(texts: List[str], model: Any, use_bert: bool = True, tokenizer: Any = None, vectorizer: Any = None) -> List[int]:\n",
    "#     \"\"\"\n",
    "#     Predict tone labels for a list of texts.\n",
    "    \n",
    "#     Args:\n",
    "#         texts (List[str]): Preprocessed texts to classify.\n",
    "#         model: Trained model (BERT Trainer or LogisticRegression).\n",
    "#         use_bert (bool): If True, use BERT model; else use Logistic Regression (default: True).\n",
    "#         tokenizer: BERT tokenizer (required if use_bert=True).\n",
    "#         vectorizer: TF-IDF vectorizer (required if use_bert=False).\n",
    "        \n",
    "#     Returns:\n",
    "#         List[int]: Predicted labels (0: creative, 1: professional, 2: technical).\n",
    "#     \"\"\"\n",
    "#     if use_bert:\n",
    "#         encodings = tokenizer(\n",
    "#             texts,\n",
    "#             padding=True,\n",
    "#             truncation=True,\n",
    "#             max_length=128,\n",
    "#             return_tensors=\"pt\"\n",
    "#         )\n",
    "#         dataset = torch.utils.data.TensorDataset(\n",
    "#             encodings['input_ids'],\n",
    "#             encodings['attention_mask']\n",
    "#         )\n",
    "#         predictions = model.predict(dataset)\n",
    "#         return np.argmax(predictions, axis=1).tolist()\n",
    "#     else:\n",
    "#         X = vectorizer.transform(texts)\n",
    "#         return model.predict(X).tolist()\n",
    "\n",
    "# def perform_tone_analysis(clients: List[Dict[str, Any]], \n",
    "#                          freelancers: List[Dict[str, Any]], \n",
    "#                          reviews: List[Dict[str, Any]], \n",
    "#                          use_bert: bool = True) -> Tuple[List[str], List[str], np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Perform tone analysis on review_text, portfolio_text, and project_description.\n",
    "    \n",
    "#     Args:\n",
    "#         clients (List[Dict[str, Any]]): Preprocessed client dictionaries.\n",
    "#         freelancers (List[Dict[str, Any]]): Preprocessed freelancer dictionaries.\n",
    "#         reviews (List[Dict[str, Any]]): Preprocessed review dictionaries.\n",
    "#         use_bert (bool): If True, use BERT classifier; else use Logistic Regression (default: True).\n",
    "        \n",
    "#     Returns:\n",
    "#         Tuple[List[str], List[str], np.ndarray]:\n",
    "#             - Client tones (e.g., ['professional', 'creative', ...]).\n",
    "#             - Freelancer tones (e.g., ['technical', 'professional', ...]).\n",
    "#             - Tone match matrix (shape: [len(clients), len(freelancers)], 1 if tones match, 0 otherwise).\n",
    "#     \"\"\"\n",
    "#     # Generate synthetic training data\n",
    "#     synthetic_texts, synthetic_labels = generate_synthetic_tone_data(num_samples_per_class=100)\n",
    "    \n",
    "#     # Add real review_text (assume manually labeled for demo)\n",
    "#     review_texts = [review['review_text'] for review in reviews]\n",
    "#     # Example: Manually label the 3 reviews (in practice, label manually or use external data)\n",
    "#     review_labels = [1, 0, 2]  # e.g., professional, creative, technical\n",
    "#     if len(review_texts) != len(review_labels):\n",
    "#         raise ValueError(\"Number of review texts and labels must match\")\n",
    "    \n",
    "#     # Combine training data\n",
    "#     train_texts = synthetic_texts + review_texts\n",
    "#     train_labels = synthetic_labels + review_labels\n",
    "    \n",
    "#     # Train classifier\n",
    "#     if use_bert:\n",
    "#         trainer = train_tone_classifier(train_texts, train_labels, use_bert=True)\n",
    "#         tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "#         model = trainer\n",
    "#         vectorizer = None\n",
    "#     else:\n",
    "#         model, vectorizer = train_tone_classifier(train_texts, train_labels, use_bert=False)\n",
    "#         tokenizer = None\n",
    "    \n",
    "#     # Predict tones\n",
    "#     tone_map = {0: 'creative', 1: 'professional', 2: 'technical'}\n",
    "    \n",
    "#     # Client tones (project_description)\n",
    "#     client_texts = [client['project_description'] for client in clients]\n",
    "#     client_tone_ids = predict_tone(client_texts, model, use_bert, tokenizer, vectorizer)\n",
    "#     client_tones = [tone_map[tid] for tid in client_tone_ids]\n",
    "    \n",
    "#     # Freelancer tones (portfolio_text, fallback to reviews if available)\n",
    "#     freelancer_tones = []\n",
    "#     for freelancer in freelancers:\n",
    "#         # Use portfolio_text (all freelancers have it)\n",
    "#         portfolio_text = freelancer['portfolio_text']\n",
    "#         portfolio_tone_id = predict_tone([portfolio_text], model, use_bert, tokenizer, vectorizer)[0]\n",
    "        \n",
    "#         # Check for reviews (optional augmentation)\n",
    "#         freelancer_reviews = [r['review_text'] for r in reviews if r['freelancer_id'] == freelancer['freelancer_id']]\n",
    "#         if freelancer_reviews:\n",
    "#             review_tone_ids = predict_tone(freelancer_reviews, model, use_bert, tokenizer, vectorizer)\n",
    "#             # Aggregate: majority vote or use portfolio_text if tied\n",
    "#             tone_counts = np.bincount(review_tone_ids + [portfolio_tone_id], minlength=3)\n",
    "#             tone_id = np.argmax(tone_counts)\n",
    "#         else:\n",
    "#             tone_id = portfolio_tone_id\n",
    "        \n",
    "#         freelancer_tones.append(tone_map[tone_id])\n",
    "    \n",
    "#     # Compute tone match matrix\n",
    "#     tone_match_matrix = np.zeros((len(clients), len(freelancers)))\n",
    "#     for i, client_tone in enumerate(client_tones):\n",
    "#         for j, freelancer_tone in enumerate(freelancer_tones):\n",
    "#             tone_match_matrix[i, j] = 1 if client_tone == freelancer_tone else 0\n",
    "    \n",
    "#     return client_tones, freelancer_tones, tone_match_matrix\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         # Load synthetic data\n",
    "#         clients_data, freelancers_data, reviews_data = load_synthetic_data(\"synthetic_data.json\")\n",
    "        \n",
    "#         # Preprocess data (join_portfolio=True for single string)\n",
    "#         clients_proc, freelancers_proc, reviews_proc = preprocess_synthetic_data(\n",
    "#             clients_data,\n",
    "#             freelancers_data,\n",
    "#             reviews_data,\n",
    "#             join_portfolio=True,\n",
    "#             include_experience=False\n",
    "#         )\n",
    "        \n",
    "#         # Perform tone analysis\n",
    "#         client_tones, freelancer_tones, tone_match_matrix = perform_tone_analysis(\n",
    "#             clients_proc,\n",
    "#             freelancers_proc,\n",
    "#             reviews_proc,\n",
    "#             use_bert=True\n",
    "#         )\n",
    "        \n",
    "#         # Print results\n",
    "#         print(\"\\nClient Tones:\")\n",
    "#         for i, tone in enumerate(client_tones, 1):\n",
    "#             print(f\"Client {i}: {tone}\")\n",
    "        \n",
    "#         print(\"\\nFreelancer Tones:\")\n",
    "#         for i, tone in enumerate(freelancer_tones, 1):\n",
    "#             print(f\"Freelancer {i}: {tone}\")\n",
    "        \n",
    "#         print(\"\\nTone Match Matrix (Client vs. Freelancer):\")\n",
    "#         for i, row in enumerate(tone_match_matrix, 1):\n",
    "#             print(f\"Client {i}: {row.tolist()}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to perform tone analysis: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de7bc6",
   "metadata": {
    "papermill": {
     "duration": 0.006047,
     "end_time": "2025-04-20T17:08:12.301782",
     "exception": false,
     "start_time": "2025-04-20T17:08:12.295735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Skill Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86f54e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:08:12.316136Z",
     "iopub.status.busy": "2025-04-20T17:08:12.315802Z",
     "iopub.status.idle": "2025-04-20T17:08:12.353719Z",
     "shell.execute_reply": "2025-04-20T17:08:12.351983Z"
    },
    "papermill": {
     "duration": 0.047077,
     "end_time": "2025-04-20T17:08:12.355155",
     "exception": false,
     "start_time": "2025-04-20T17:08:12.308078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 clients, 10 freelancers, and 3 reviews from synthetic_data.json\n",
      "\n",
      "Skill Labels:\n",
      "['React', 'JavaScript', 'Node.js', 'Python', 'Django', 'Flask', 'Graphic Design', 'Illustration', 'UI/UX Design', 'Data Visualization', 'TypeScript', 'Tailwind CSS', 'Animation', 'Machine Learning', 'SQL']\n",
      "\n",
      "Sample Client Skill Vector (Client 1):\n",
      "[0 0 0 1 1 0 0 0 0 1 0 0 1 0 0]\n",
      "\n",
      "Sample Freelancer Skill Vector (Freelancer 1):\n",
      "[0 0 1 0 1 0 0 0 0 1 1 1 0 0 0]\n",
      "\n",
      "Skill Similarity Matrix (Client vs. Freelancer):\n",
      "Client 1: ['0.2857', '0.5000', '0.3333', '0.1667', '0.4000', '0.1429', '0.4000', '0.2857', '0.0000', '0.0000']\n",
      "Client 2: ['0.1250', '0.0000', '0.0000', '0.0000', '0.1667', '0.1429', '0.1667', '0.0000', '0.1250', '0.1429']\n",
      "Client 3: ['0.1429', '0.1429', '0.7500', '0.0000', '0.0000', '0.1667', '0.2000', '0.1429', '0.3333', '0.0000']\n",
      "Client 4: ['0.3333', '0.3333', '0.0000', '0.0000', '0.2000', '0.0000', '0.2000', '0.3333', '0.1429', '0.1667']\n",
      "Client 5: ['0.2857', '0.1250', '0.6000', '0.1667', '0.1667', '0.3333', '0.1667', '0.0000', '0.2857', '0.0000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from typing import List, Dict, Any, Tuple, Union\n",
    "from fuzzywuzzy import fuzz\n",
    "import itertools\n",
    "\n",
    "# Define skill universe (from data generation script, April 20, 2025)\n",
    "SKILLS_POOL = [\n",
    "    \"React\", \"JavaScript\", \"Node.js\", \"Python\", \"Django\", \"Flask\",\n",
    "    \"Graphic Design\", \"Illustration\", \"UI/UX Design\", \"Data Visualization\",\n",
    "    \"TypeScript\", \"Tailwind CSS\", \"Animation\", \"Machine Learning\", \"SQL\"\n",
    "]\n",
    "\n",
    "def extract_skill_features(clients: List[Dict[str, Any]], \n",
    "                          freelancers: List[Dict[str, Any]], \n",
    "                          use_one_hot: bool = True) -> Tuple[Union[np.ndarray, List[set]], Union[np.ndarray, List[set]], List[str]]:\n",
    "    \"\"\"\n",
    "    Extract skill features as one-hot encoded vectors or skill sets.\n",
    "    \n",
    "    Args:\n",
    "        clients (List[Dict[str, Any]]): Client dictionaries with 'skills_required'.\n",
    "        freelancers (List[Dict[str, Any]]): Freelancer dictionaries with 'skills'.\n",
    "        use_one_hot (bool): If True, use one-hot encoding; else return skill sets (default: True).\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[Union[np.ndarray, List[set]], Union[np.ndarray, List[set]], List[str]]:\n",
    "            - Client skill features (array of shape [num_clients, num_skills] or list of sets).\n",
    "            - Freelancer skill features (array of shape [num_freelancers, num_skills] or list of sets).\n",
    "            - Skill labels (list of skill names, only for one-hot encoding).\n",
    "    \"\"\"\n",
    "    # Extract skill lists\n",
    "    client_skills = [client['skills_required'] for client in clients]\n",
    "    freelancer_skills = [freelancer['skills'] for freelancer in freelancers]\n",
    "    \n",
    "    if use_one_hot:\n",
    "        # Initialize MultiLabelBinarizer with predefined skill universe\n",
    "        mlb = MultiLabelBinarizer(classes=SKILLS_POOL)\n",
    "        \n",
    "        # Fit and transform skills\n",
    "        client_features = mlb.fit_transform(client_skills)\n",
    "        freelancer_features = mlb.transform(freelancer_skills)\n",
    "        \n",
    "        return client_features, freelancer_features, mlb.classes_.tolist()\n",
    "    else:\n",
    "        # Return skill sets for exact matching\n",
    "        client_features = [set(skills) for skills in client_skills]\n",
    "        freelancer_features = [set(skills) for skills in freelancer_skills]\n",
    "        return client_features, freelancer_features, SKILLS_POOL\n",
    "\n",
    "def compute_skill_similarity(clients: List[Dict[str, Any]], \n",
    "                            freelancers: List[Dict[str, Any]], \n",
    "                            use_one_hot: bool = True, \n",
    "                            use_fuzzy: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute skill similarity between clients and freelancers using Jaccard similarity.\n",
    "    \n",
    "    Args:\n",
    "        clients (List[Dict[str, Any]]): Client dictionaries with 'skills_required'.\n",
    "        freelancers (List[Dict[str, Any]]): Freelancer dictionaries with 'skills'.\n",
    "        use_one_hot (bool): If True, use one-hot encoded vectors; else use set-based Jaccard (default: True).\n",
    "        use_fuzzy (bool): If True, use fuzzy matching for skills (default: False).\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Similarity matrix (shape: [num_clients, num_freelancers]).\n",
    "    \"\"\"\n",
    "    # Extract skill features\n",
    "    client_features, freelancer_features, skill_labels = extract_skill_features(clients, freelancers, use_one_hot)\n",
    "    \n",
    "    # Initialize similarity matrix\n",
    "    similarity_matrix = np.zeros((len(clients), len(freelancers)))\n",
    "    \n",
    "    if use_one_hot and not use_fuzzy:\n",
    "        # Jaccard similarity on one-hot vectors\n",
    "        for i, client_vec in enumerate(client_features):\n",
    "            for j, freelancer_vec in enumerate(freelancer_features):\n",
    "                intersection = np.sum(client_vec & freelancer_vec)\n",
    "                union = np.sum(client_vec | freelancer_vec)\n",
    "                similarity_matrix[i, j] = intersection / union if union > 0 else 0.0\n",
    "    else:\n",
    "        # Set-based Jaccard similarity\n",
    "        for i, client_skills in enumerate(client_features):\n",
    "            for j, freelancer_skills in enumerate(freelancer_features):\n",
    "                if use_fuzzy:\n",
    "                    # Fuzzy matching: Compute max similarity for each skill pair\n",
    "                    intersection = 0\n",
    "                    for c_skill, f_skill in itertools.product(client_skills, freelancer_skills):\n",
    "                        score = fuzz.ratio(c_skill.lower(), f_skill.lower()) / 100.0\n",
    "                        if score > 0.9:  # Threshold for match\n",
    "                            intersection += 1\n",
    "                    union = len(client_skills) + len(freelancer_skills) - intersection\n",
    "                    similarity_matrix[i, j] = intersection / union if union > 0 else 0.0\n",
    "                else:\n",
    "                    # Exact matching\n",
    "                    intersection = len(client_skills & freelancer_skills)\n",
    "                    union = len(client_skills | freelancer_skills)\n",
    "                    similarity_matrix[i, j] = intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load synthetic data\n",
    "        clients_data, freelancers_data, reviews_data = load_synthetic_data(\"synthetic_data.json\")\n",
    "        \n",
    "        # Extract skill features\n",
    "        client_features, freelancer_features, skill_labels = extract_skill_features(\n",
    "            clients_data,\n",
    "            freelancers_data,\n",
    "            use_one_hot=True\n",
    "        )\n",
    "        \n",
    "        # Compute skill similarity\n",
    "        similarity_matrix = compute_skill_similarity(\n",
    "            clients_data,\n",
    "            freelancers_data,\n",
    "            use_one_hot=True,\n",
    "            use_fuzzy=False\n",
    "        )\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nSkill Labels:\")\n",
    "        print(skill_labels)\n",
    "        \n",
    "        print(\"\\nSample Client Skill Vector (Client 1):\")\n",
    "        print(client_features[0])\n",
    "        \n",
    "        print(\"\\nSample Freelancer Skill Vector (Freelancer 1):\")\n",
    "        print(freelancer_features[0])\n",
    "        \n",
    "        print(\"\\nSkill Similarity Matrix (Client vs. Freelancer):\")\n",
    "        for i, row in enumerate(similarity_matrix, 1):\n",
    "            print(f\"Client {i}: {[f'{x:.4f}' for x in row]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process skills: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d2611",
   "metadata": {
    "papermill": {
     "duration": 0.005938,
     "end_time": "2025-04-20T17:08:12.368125",
     "exception": false,
     "start_time": "2025-04-20T17:08:12.362187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get similarity for a client with each freelancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b97c3cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:08:12.382537Z",
     "iopub.status.busy": "2025-04-20T17:08:12.382139Z",
     "iopub.status.idle": "2025-04-20T17:08:12.393737Z",
     "shell.execute_reply": "2025-04-20T17:08:12.392649Z"
    },
    "papermill": {
     "duration": 0.020816,
     "end_time": "2025-04-20T17:08:12.395210",
     "exception": false,
     "start_time": "2025-04-20T17:08:12.374394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 clients, 10 freelancers, and 3 reviews from synthetic_data.json\n",
      "\n",
      "Skill Similarity Scores for Client vs. Freelancers:\n",
      "Freelancer 1: 0.0000\n",
      "Freelancer 2: 0.1429\n",
      "Freelancer 3: 0.0000\n",
      "Freelancer 4: 0.2000\n",
      "Freelancer 5: 0.2000\n",
      "Freelancer 6: 0.0000\n",
      "Freelancer 7: 0.0000\n",
      "Freelancer 8: 0.1429\n",
      "Freelancer 9: 0.1429\n",
      "Freelancer 10: 0.1667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from fuzzywuzzy import fuzz\n",
    "import itertools\n",
    "\n",
    "def compute_client_skill_similarity(client_skills: List[str], \n",
    "                                   freelancers_data: List[Dict[str, Any]] = None, \n",
    "                                   use_fuzzy: bool = False) -> List[float]:\n",
    "    \"\"\"\n",
    "    Compute Jaccard similarity between a client's skills and each freelancer's skills.\n",
    "    \n",
    "    Args:\n",
    "        client_skills (List[str]): List of client skills (e.g., ['React', 'JavaScript']).\n",
    "        freelancers_data (List[Dict[str, Any]]): Preprocessed freelancer data (optional, loaded if not provided).\n",
    "        use_fuzzy (bool): If True, use fuzzy matching for skills (default: False).\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: Jaccard similarity scores for each freelancer (ordered by freelancer_id).\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If client_skills is empty.\n",
    "        FileNotFoundError: If freelancers_data is not provided and synthetic_data.json is missing.\n",
    "    \"\"\"\n",
    "    # Validate client skills\n",
    "    if not client_skills:\n",
    "        raise ValueError(\"client_skills cannot be empty\")\n",
    "    \n",
    "    # Load freelancer data if not provided\n",
    "    if freelancers_data is None:\n",
    "        try:\n",
    "            _, freelancers_data, _ = load_synthetic_data(\"synthetic_data.json\")\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"synthetic_data.json not found and freelancers_data not provided\")\n",
    "    \n",
    "    # Convert client skills to set\n",
    "    client_skills_set = set(client_skills)\n",
    "    \n",
    "    # Initialize similarity scores\n",
    "    similarity_scores = []\n",
    "    \n",
    "    # Compute similarity for each freelancer\n",
    "    for freelancer in freelancers_data:\n",
    "        freelancer_skills = set(freelancer['skills'])\n",
    "        \n",
    "        if use_fuzzy:\n",
    "            # Fuzzy matching: Compute max similarity for each skill pair\n",
    "            intersection = 0\n",
    "            for c_skill, f_skill in itertools.product(client_skills, freelancer_skills):\n",
    "                score = fuzz.ratio(c_skill.lower(), f_skill.lower()) / 100.0\n",
    "                if score > 0.9:  # Threshold for match\n",
    "                    intersection += 1\n",
    "            union = len(client_skills) + len(freelancer_skills) - intersection\n",
    "            similarity = intersection / union if union > 0 else 0.0\n",
    "        else:\n",
    "            # Exact matching\n",
    "            intersection = len(client_skills_set & freelancer_skills)\n",
    "            union = len(client_skills_set | freelancer_skills)\n",
    "            similarity = intersection / union if union > 0 else 0.0\n",
    "        \n",
    "        similarity_scores.append(similarity)\n",
    "    \n",
    "    return similarity_scores\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load synthetic data\n",
    "        _, freelancers_data, _ = load_synthetic_data(\"synthetic_data.json\")\n",
    "        \n",
    "        # Example client skills\n",
    "        new_client_skills = [\"React\", \"JavaScript\", \"UI/UX Design\"]\n",
    "        \n",
    "        # Compute skill similarity\n",
    "        similarity_scores = compute_client_skill_similarity(\n",
    "            client_skills=new_client_skills,\n",
    "            freelancers_data=freelancers_data,\n",
    "            use_fuzzy=False\n",
    "        )\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nSkill Similarity Scores for Client vs. Freelancers:\")\n",
    "        for i, score in enumerate(similarity_scores, 1):\n",
    "            print(f\"Freelancer {i}: {score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compute skill similarities: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd39c9a",
   "metadata": {
    "papermill": {
     "duration": 0.005956,
     "end_time": "2025-04-20T17:08:12.407509",
     "exception": false,
     "start_time": "2025-04-20T17:08:12.401553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Calculating final score from a client for each freelancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cd571ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:08:12.421411Z",
     "iopub.status.busy": "2025-04-20T17:08:12.421050Z",
     "iopub.status.idle": "2025-04-20T17:08:12.695995Z",
     "shell.execute_reply": "2025-04-20T17:08:12.695005Z"
    },
    "papermill": {
     "duration": 0.284148,
     "end_time": "2025-04-20T17:08:12.697755",
     "exception": false,
     "start_time": "2025-04-20T17:08:12.413607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 clients, 10 freelancers, and 3 reviews from synthetic_data.json\n",
      "\n",
      "Top 5 Matches:\n",
      "1. Freelancer 2 with score 0.7361\n",
      "2. Freelancer 7 with score 0.7240\n",
      "3. Freelancer 1 with score 0.6795\n",
      "4. Freelancer 8 with score 0.6670\n",
      "5. Freelancer 3 with score 0.6561\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def compute_final_score(client_data: Dict[str, Any], \n",
    "                       freelancers_data: List[Dict[str, Any]] = None,\n",
    "                       freelancer_embeddings_file: str = \"freelancer_embeddings.npy\",\n",
    "                       weights: Dict[str, float] = None) -> List[float]:\n",
    "    \"\"\"\n",
    "    Compute final score for a client against each freelancer based on text similarity,\n",
    "    skill similarity, and average rating.\n",
    "    \n",
    "    Args:\n",
    "        client_data (Dict[str, Any]): Client data with 'project_description' and 'skills_required'.\n",
    "        freelancers_data (List[Dict[str, Any]]): Preprocessed freelancer data (optional, loaded if not provided).\n",
    "        freelancer_embeddings_file (str): Path to precomputed freelancer embeddings (default: 'freelancer_embeddings.npy').\n",
    "        weights (Dict[str, float]): Weights for scoring components (default: {'skill': 0.4, 'text': 0.4, 'rating': 0.2}).\n",
    "        \n",
    "    Returns:\n",
    "        List[float]: Final scores for each freelancer (ordered by freelancer_id).\n",
    "        \n",
    "    Raises:\n",
    "        KeyError: If required client_data keys are missing.\n",
    "        FileNotFoundError: If freelancers_data or embeddings file is missing.\n",
    "        ValueError: If weights are invalid.\n",
    "    \"\"\"\n",
    "    # Validate client data\n",
    "    required_keys = ['project_description', 'skills_required']\n",
    "    missing_keys = [key for key in required_keys if key not in client_data]\n",
    "    if missing_keys:\n",
    "        raise KeyError(f\"client_data missing required keys: {missing_keys}\")\n",
    "    \n",
    "    # Load freelancer data if not provided\n",
    "    if freelancers_data is None:\n",
    "        try:\n",
    "            _, freelancers_data, _ = load_synthetic_data(\"synthetic_data.json\")\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"synthetic_data.json not found and freelancers_data not provided\")\n",
    "    \n",
    "    # Set default weights\n",
    "    if weights is None:\n",
    "        weights = {'skill': 0.4, 'text': 0.4, 'rating': 0.2}\n",
    "    \n",
    "    # Validate weights\n",
    "    if not all(k in weights for k in ['skill', 'text', 'rating']):\n",
    "        raise ValueError(\"weights must include 'skill', 'text', and 'rating'\")\n",
    "    if not abs(sum(weights.values()) - 1.0) < 1e-6:\n",
    "        raise ValueError(\"weights must sum to 1.0\")\n",
    "    if any(w < 0 for w in weights.values()):\n",
    "        raise ValueError(\"weights must be non-negative\")\n",
    "    \n",
    "    # Compute text similarity\n",
    "    text_similarities = compute_client_similarity(\n",
    "        client_data=client_data,\n",
    "        freelancer_embeddings_file=freelancer_embeddings_file,\n",
    "        freelancers_data=freelancers_data\n",
    "    )\n",
    "    \n",
    "    # Compute skill similarity\n",
    "    skill_similarities = compute_client_skill_similarity(\n",
    "        client_skills=client_data['skills_required'],\n",
    "        freelancers_data=freelancers_data,\n",
    "        use_fuzzy=False\n",
    "    )\n",
    "    \n",
    "    # Extract and normalize average ratings (assume max rating is 5.0)\n",
    "    ratings = [freelancer['avg_rating'] / 5.0 for freelancer in freelancers_data]\n",
    "    \n",
    "    # Compute final scores\n",
    "    final_scores = [\n",
    "        weights['skill'] * skill_sim + weights['text'] * text_sim + weights['rating'] * rating\n",
    "        for skill_sim, text_sim, rating in zip(skill_similarities, text_similarities, ratings)\n",
    "    ]\n",
    "    \n",
    "    return final_scores\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load synthetic data\n",
    "        clients_data, freelancers_data, _ = load_synthetic_data(\"synthetic_data.json\")\n",
    "        \n",
    "        # Example client data\n",
    "        new_client = {\n",
    "            \"project_description\": \"Build a React e-commerce website with modern UI/UX\",\n",
    "            \"skills_required\": [\"React\", \"JavaScript\", \"UI/UX Design\"]\n",
    "        }\n",
    "\n",
    "        new_client = clients_data[0]\n",
    "        \n",
    "        # Compute final scores\n",
    "        final_scores = compute_final_score(\n",
    "            client_data=new_client,\n",
    "            freelancers_data=freelancers_data,\n",
    "            freelancer_embeddings_file=\"freelancer_embeddings.npy\",\n",
    "            weights={'skill': 0.4, 'text': 0.4, 'rating': 0.2}\n",
    "        )\n",
    "        \n",
    "        # Print results\n",
    "        top_5_indices = np.argsort(final_scores)[-5:][::-1]  # reverse for descending order\n",
    "        print(\"\\nTop 5 Matches:\")\n",
    "        for rank, idx in enumerate(top_5_indices, 1):\n",
    "            print(f\"{rank}. Freelancer {idx+1} with score {final_scores[idx]:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compute final scores: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 69.194872,
   "end_time": "2025-04-20T17:08:15.592674",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-20T17:07:06.397802",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01c4482458a2482f901a464f8e2a44a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7c366a098051428ea418932febc3b328",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8021c4bbfea64bbbaceb79c51783e5a7",
       "tabbable": null,
       "tooltip": null,
       "value": 231508.0
      }
     },
     "029eca8fcd574796989a58b2e3e54036": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "05ac336d991346adb19000b94515ebf4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "09a6e2ed2eb6491bbb1438fe1723756c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0c4b85057d5045648ff06ea9a2a88b94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dd1b3e03c52c41fda9123a7bc24d5d7c",
       "placeholder": "​",
       "style": "IPY_MODEL_df86b7f27b5146da990c16a39383c3ef",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "120916794d4344f6bc82d7ad07832dc8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "16c592ae24a84cd0b330b52ceb346448": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1828e0a126c5484495d0e6d7a3647fca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1d2052e291fa4a75b5558bd45316253c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3d28863c029c42fe99dce7f9de2c389d",
       "placeholder": "​",
       "style": "IPY_MODEL_c3f7c3e6ece14aecab9a88d5e5057d9c",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "1ea7ba1c563448c08b56ac5683dabee0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2a6e14af7c2248a192ab5d86f365c08b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f37629f53434ff3855b85f568a83688": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3bfabd0f8d7d4048be31e6f282e6adf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0c4b85057d5045648ff06ea9a2a88b94",
        "IPY_MODEL_3c9ab947272c4ab6b3503ec08a79915f",
        "IPY_MODEL_5a7d0bda71c043df87d1fd4bf5f7d9f1"
       ],
       "layout": "IPY_MODEL_62c8eae6cb2d49c38915dd32f632c6ca",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3c9ab947272c4ab6b3503ec08a79915f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_05ac336d991346adb19000b94515ebf4",
       "max": 483.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a8cb266ee58349be93d7dec8471e66b3",
       "tabbable": null,
       "tooltip": null,
       "value": 483.0
      }
     },
     "3d28863c029c42fe99dce7f9de2c389d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d640c676ace4f15a9fc7024ad5fa13c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4013407054524766b45bf21630aaec2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6c4ea40951194cf19f596b6269d1a8b9",
        "IPY_MODEL_6ee63396fac64ac487e9a2ba2aa751e8",
        "IPY_MODEL_66970c9d0d9c4330a301b88c593562dc"
       ],
       "layout": "IPY_MODEL_54836eeccf8f42bfbf7736221d5179cf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "401490ca8b6d4f5dad1e8b8348446d36": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "403b20c4e1814d8eb3f2bb1170a03f42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5bf8a5c4fc504b69be50c4a4f8a810ad",
        "IPY_MODEL_01c4482458a2482f901a464f8e2a44a1",
        "IPY_MODEL_61ad902d8d214f3c90026f9bc3e5e66e"
       ],
       "layout": "IPY_MODEL_2a6e14af7c2248a192ab5d86f365c08b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "417203c001544d55ab7d7ac32fc35a1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "43abe90023634d1e878fa558c34c600c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "484cd66c8eeb4046ba681bdb58b102d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4bdb7a3798a1412084feb3a0c3aaba78": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "518e465c382749e780243b8218e0271c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1d2052e291fa4a75b5558bd45316253c",
        "IPY_MODEL_d678b1053513474f895d1cf0c674a567",
        "IPY_MODEL_da0cd886dc36436a908e97174465cbbd"
       ],
       "layout": "IPY_MODEL_e0977730c4314714b337c869a00462a7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "54836eeccf8f42bfbf7736221d5179cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a7d0bda71c043df87d1fd4bf5f7d9f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_976113c59b2540cba47c0675102ec3a0",
       "placeholder": "​",
       "style": "IPY_MODEL_a3da33081696491789df1e91bfb085ac",
       "tabbable": null,
       "tooltip": null,
       "value": " 483/483 [00:00&lt;00:00, 39.1kB/s]"
      }
     },
     "5bf8a5c4fc504b69be50c4a4f8a810ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2f37629f53434ff3855b85f568a83688",
       "placeholder": "​",
       "style": "IPY_MODEL_029eca8fcd574796989a58b2e3e54036",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "60eae6fd6a914176ba8dd4e359181593": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "61ad902d8d214f3c90026f9bc3e5e66e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_43abe90023634d1e878fa558c34c600c",
       "placeholder": "​",
       "style": "IPY_MODEL_1828e0a126c5484495d0e6d7a3647fca",
       "tabbable": null,
       "tooltip": null,
       "value": " 232k/232k [00:00&lt;00:00, 5.68MB/s]"
      }
     },
     "62c8eae6cb2d49c38915dd32f632c6ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66970c9d0d9c4330a301b88c593562dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d36abf1afc294093a9ca7f14c5ca8ff1",
       "placeholder": "​",
       "style": "IPY_MODEL_86135e4ac7e64375b51dd440646cb3cd",
       "tabbable": null,
       "tooltip": null,
       "value": " 268M/268M [00:01&lt;00:00, 221MB/s]"
      }
     },
     "6c4ea40951194cf19f596b6269d1a8b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3d640c676ace4f15a9fc7024ad5fa13c",
       "placeholder": "​",
       "style": "IPY_MODEL_16c592ae24a84cd0b330b52ceb346448",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "6ee63396fac64ac487e9a2ba2aa751e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_401490ca8b6d4f5dad1e8b8348446d36",
       "max": 267954768.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ea7ba1c563448c08b56ac5683dabee0",
       "tabbable": null,
       "tooltip": null,
       "value": 267954768.0
      }
     },
     "7c366a098051428ea418932febc3b328": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8021c4bbfea64bbbaceb79c51783e5a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "86135e4ac7e64375b51dd440646cb3cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "976113c59b2540cba47c0675102ec3a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a3da33081696491789df1e91bfb085ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a8cb266ee58349be93d7dec8471e66b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ae9c25e13dc948be9ea08502aa35bf92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_120916794d4344f6bc82d7ad07832dc8",
       "placeholder": "​",
       "style": "IPY_MODEL_09a6e2ed2eb6491bbb1438fe1723756c",
       "tabbable": null,
       "tooltip": null,
       "value": " 466k/466k [00:00&lt;00:00, 10.9MB/s]"
      }
     },
     "b8238afa3a9e47fa8d90a15c20165e33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b9a8a52f3c744be0acb3b959af7768ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_60eae6fd6a914176ba8dd4e359181593",
       "max": 466062.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d8f9ead146cb48fc84b3f409fa87b1ad",
       "tabbable": null,
       "tooltip": null,
       "value": 466062.0
      }
     },
     "be5e632973bb457996ed0ac2a218fa53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_df353e44cc1f4c9f85bb2965c4c49cf3",
        "IPY_MODEL_b9a8a52f3c744be0acb3b959af7768ce",
        "IPY_MODEL_ae9c25e13dc948be9ea08502aa35bf92"
       ],
       "layout": "IPY_MODEL_4bdb7a3798a1412084feb3a0c3aaba78",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c3f7c3e6ece14aecab9a88d5e5057d9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d36abf1afc294093a9ca7f14c5ca8ff1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4e4fcf7b3844093a7578f81e3229cb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d678b1053513474f895d1cf0c674a567": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ede265f9e8cc4e728488169fd52791ea",
       "max": 48.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_484cd66c8eeb4046ba681bdb58b102d8",
       "tabbable": null,
       "tooltip": null,
       "value": 48.0
      }
     },
     "d8f9ead146cb48fc84b3f409fa87b1ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "da0cd886dc36436a908e97174465cbbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ee6e2a712512431ab04169d43f8dea91",
       "placeholder": "​",
       "style": "IPY_MODEL_417203c001544d55ab7d7ac32fc35a1f",
       "tabbable": null,
       "tooltip": null,
       "value": " 48.0/48.0 [00:00&lt;00:00, 3.79kB/s]"
      }
     },
     "dd1b3e03c52c41fda9123a7bc24d5d7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df353e44cc1f4c9f85bb2965c4c49cf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b8238afa3a9e47fa8d90a15c20165e33",
       "placeholder": "​",
       "style": "IPY_MODEL_d4e4fcf7b3844093a7578f81e3229cb3",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "df86b7f27b5146da990c16a39383c3ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e0977730c4314714b337c869a00462a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ede265f9e8cc4e728488169fd52791ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee6e2a712512431ab04169d43f8dea91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
