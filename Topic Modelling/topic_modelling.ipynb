{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e4988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora, models\n",
    "from bertopic import BERTopic\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"posts\": [\n",
    "        \"Looking for a mentor to guide me in deep learning projects.\",\n",
    "        \"Anyone up for a study group for GRE preparation?\",\n",
    "        \"Hosting a workshop on React and Web Development!\",\n",
    "        \"How can I improve my resume for data science internships?\",\n",
    "        \"Is anyone teaching graphic design or Photoshop?\",\n",
    "        \"Letâ€™s collaborate on a blockchain-based project.\",\n",
    "        \"Discussion on mental health and academic pressure.\",\n",
    "        \"Career opportunities in AI and ML are booming lately.\",\n",
    "        \"Organizing a mock interview session for placements.\",\n",
    "        \"Python for beginners â€” starting from basics this week!\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Sample Forum Data:\\n\", df.head())\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"clean_text\"] = df[\"posts\"].apply(clean_text)\n",
    "\n",
    "\n",
    "# Tokenize for gensim\n",
    "texts = [text.split() for text in df[\"clean_text\"]]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# LDA Model\n",
    "lda_model = models.LdaModel(\n",
    "    corpus,\n",
    "    num_topics=4,\n",
    "    id2word=dictionary,\n",
    "    passes=15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Print Topics\n",
    "print(\"\\nðŸ”¹ LDA Topics:\")\n",
    "for idx, topic in lda_model.print_topics(num_words=5):\n",
    "    print(f\"Topic {idx + 1}: {topic}\")\n",
    "\n",
    "\n",
    "for idx, topic in lda_model.show_topics(formatted=False, num_words=10):\n",
    "    wc = WordCloud(background_color=\"white\", width=600, height=400)\n",
    "    topic_words = dict(topic)\n",
    "    plt.figure()\n",
    "    plt.imshow(wc.generate_from_frequencies(topic_words))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Topic {idx + 1}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Initialize and Fit BERTopic\n",
    "topic_model = BERTopic(language=\"english\", verbose=False)\n",
    "topics, probs = topic_model.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "# Display Discovered Topics\n",
    "print(\"\\nðŸ”¹ BERTopic Discovered Topics:\")\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info.head())\n",
    "\n",
    "\n",
    "topic_freq = topic_info[[\"Topic\", \"Count\"]].head(10)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.barh(topic_freq[\"Topic\"].astype(str), topic_freq[\"Count\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Number of Posts\")\n",
    "plt.ylabel(\"Topic ID\")\n",
    "plt.title(\"Top Trending Topics on the Platform\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_post = \"Anyone organizing a machine learning workshop?\"\n",
    "topic_pred, prob = topic_model.transform([sample_post])\n",
    "topic_label = topic_model.get_topic(topic_pred[0])\n",
    "\n",
    "print(\"\\nSample Post:\", sample_post)\n",
    "print(\"Predicted Topic Keywords:\", topic_label)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
